{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building an Autoencoder roughly based on the U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import datetime\n",
    "from skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start by loading two of the images in. Then I will select from the originals each only one. Aftwards, I will select the 500 images in good and bad quality from the two image and create the classification label for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"/scratch2/ttoebro/data/X_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16220, 256, 256, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.load('/scratch2/ttoebro/data/Y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16220, 256, 256, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean up the mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16220, 256, 256, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(tensor_in, name_layer, is_training):\n",
    "    x = tf.layers.conv2d(\n",
    "    inputs = tensor_in,\n",
    "    filters = 64,\n",
    "    kernel_size = [3, 3],\n",
    "    padding = \"same\",\n",
    "    activation= None,\n",
    "    name = name_layer)\n",
    "    \n",
    "    x = tf.layers.batch_normalization(x, name = name_layer + \"_bn\",\n",
    "                             center=True, \n",
    "                             scale=True, \n",
    "                             training=is_training)\n",
    "    \n",
    "    return tf.nn.relu(x, name = name_layer + \"_relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutoEncoder_model(features, labels, mode):\n",
    "\t# Input Layer\n",
    "\tinput_layer = features['x']\n",
    "\n",
    "\t# Convolutional layer #1     \n",
    "\tconv1 = tf.layers.conv2d(\n",
    "\tinputs = input_layer,\n",
    "\tfilters = 64,\n",
    "\tkernel_size = 3,\n",
    "\tpadding = \"same\",\n",
    "\tactivation= tf.nn.relu,\n",
    "\tname = \"Conv_1\")\n",
    "\tis_training_mode = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "\t# 18 of the middle layers with Convolution, batch normalization and afterwards ReLu\n",
    "\tconv2 = conv_layer(conv1, \"conv2\", is_training = is_training_mode)\n",
    "\tconv3 = conv_layer(conv2, \"conv3\", is_training = is_training_mode)\n",
    "\tconv4 = conv_layer(conv3, \"conv4\", is_training = is_training_mode)\n",
    "\tconv5 = conv_layer(conv4, \"conv5\", is_training = is_training_mode)\n",
    "\tconv6 = conv_layer(conv5, \"conv6\", is_training = is_training_mode)\n",
    "\tconv7 = conv_layer(conv6, \"conv7\", is_training = is_training_mode)\n",
    "\tconv8 = conv_layer(conv7, \"conv8\", is_training = is_training_mode)\n",
    "\tconv9 = conv_layer(conv8, \"conv9\", is_training = is_training_mode)\n",
    "\tconv10 = conv_layer(conv9, \"conv10\", is_training = is_training_mode)\n",
    "\tconv11 = conv_layer(conv10, \"conv11\", is_training = is_training_mode)\n",
    "\tconv12 = conv_layer(conv11, \"conv12\", is_training = is_training_mode)\n",
    "\tconv13 = conv_layer(conv12, \"conv13\", is_training = is_training_mode)\n",
    "\tconv14 = conv_layer(conv13, \"conv14\", is_training = is_training_mode)\n",
    "\tconv15 = conv_layer(conv14, \"conv15\", is_training = is_training_mode)\n",
    "\tconv16 = conv_layer(conv15, \"conv16\", is_training = is_training_mode)\n",
    "\tconv17 = conv_layer(conv16, \"conv17\", is_training = is_training_mode)\n",
    "\tconv18 = conv_layer(conv17, \"conv18\", is_training = is_training_mode)\n",
    "\tconv19 = conv_layer(conv18, \"conv19\", is_training = is_training_mode)\n",
    "\n",
    "\t# final \n",
    "\tfinal_layer = tf.layers.conv2d(\n",
    "\tinputs = conv19,\n",
    "\tfilters = 1,\n",
    "\tkernel_size = [1, 1],\n",
    "\tpadding = \"same\",\n",
    "\tactivation = None,\n",
    "\tname = \"final_layer\") + input_layer\n",
    "\n",
    "\n",
    "\tif not (mode == tf.estimator.ModeKeys.PREDICT):\n",
    "\t# Output all learnable variables for tensorboard\n",
    "\t\tfor var in tf.trainable_variables():\n",
    "\t\t\tname = var.name\n",
    "\t\t\tname = name.replace(':', '_')\n",
    "\t\t\ttf.summary.histogram(name, var)\n",
    "\t\t\tmerged_summary = tf.summary.merge_all()\n",
    "\n",
    "\tif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\t\ttf.summary.image(\"Input_Image\", input_layer, max_outputs = 1)\n",
    "\t\ttf.summary.image(\"Output_Image\", final_layer, max_outputs = 1)\n",
    "\t\ttf.summary.image(\"True_Image\", labels,  max_outputs = 1)\n",
    "\t\ttf.summary.histogram(\"Summary_final_layer\", final_layer)\n",
    "\t\ttf.summary.histogram(\"Summary_labels\", labels)\n",
    "\n",
    "\t# Give output in prediction mode\n",
    "\tif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "\t\treturn tf.estimator.EstimatorSpec(mode = mode, predictions=final_layer)\n",
    "\n",
    "\n",
    "\t# Calculate Loss (for both Train and EVAL modes)\n",
    "\t# See that the residual learning is implemented here.\n",
    "\tloss = tf.losses.mean_squared_error(labels = labels , predictions = final_layer)\n",
    "\ttf.summary.scalar(\"Value_Loss_Function\", loss)\n",
    "\n",
    "\t# Configure Learning when training.\n",
    "\tif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\t\tupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\t\twith tf.control_dependencies(update_ops):\n",
    "\t\t\toriginal_optimizer = tf.train.AdamOptimizer(learning_rate =  0.015)\n",
    "\t\t\toptimizer = tf.contrib.estimator.clip_gradients_by_norm(original_optimizer, clip_norm=5.0)\n",
    "\t\t\ttrain_op = optimizer.minimize(loss = loss, global_step=tf.train.get_global_step())\n",
    "\t\t\treturn tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "runconf = tf.estimator.RunConfig(save_summary_steps=5, log_step_count_steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/cloud/model/DnCNN_V2_run2', '_tf_random_seed': None, '_save_summary_steps': 5, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2aded820f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "AutoEncoder = tf.estimator.Estimator(config=runconf,\n",
    "    model_fn=AutoEncoder_model, model_dir=\"/home/cloud/model/DnCNN_V2_run2\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an original image. What does our network predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and print results\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X[:,:,:,:]},\n",
    "    y=Y[:,:,:,:],\n",
    "    batch_size = 1,\n",
    "    shuffle=False)\n",
    "predict_results = AutoEncoder.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mae = 0\n",
    "sum_mse = 0\n",
    "sum_ssim = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/cloud/model/DnCNN_V2_run2/model.ckpt-460424\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/.local/lib/python3.6/site-packages/skimage/util/arraypad.py:1537: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current mae is 0.45157787576317787 and mse is 0.03412065940210596and ssim is 11.207649756957215 at picture 0\n",
      "Current mae is 19.38286216650158 and mse is 1.6363085248158313and ssim is 441.5802112630384 at picture 500\n",
      "Current mae is 38.33904817793518 and mse is 3.2469307276187465and ssim is 871.5490816652876 at picture 1000\n",
      "Current mae is 57.138087663799524 and mse is 4.943503115151543and ssim is 1302.1881063322892 at picture 1500\n",
      "Current mae is 75.48390480037779 and mse is 6.4783701652195305and ssim is 1737.8818674178283 at picture 2000\n"
     ]
    }
   ],
   "source": [
    "for im_num in range(0, Y.shape[0]):\n",
    "    prediction = next(predict_results)\n",
    "    true_image = Y[im_num,:,:,:]\n",
    "    sum_mae += np.mean(np.abs(prediction - true_image))\n",
    "    sum_mse += np.mean(np.power((prediction - true_image), 2))\n",
    "    sum_ssim += skimage.measure.compare_ssim(prediction[:,:,0],  true_image[:,:,0])\n",
    "    if(im_num % 500 == 0):\n",
    "        print(\"Current mae is \" + str(sum_mae) + \" and mse is \" + str(sum_mse) + \" and ssim is \" + str(sum_ssim) + \" at picture \" + str(im_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609.3114349963143\n"
     ]
    }
   ],
   "source": [
    "print(sum_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.306891682586865\n"
     ]
    }
   ],
   "source": [
    "print(sum_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13988.92104118699\n"
     ]
    }
   ],
   "source": [
    "print(sum_ssim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
